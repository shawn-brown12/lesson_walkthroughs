{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c9d2e2-0b2e-4b7b-a784-5665a3f6a767",
   "metadata": {},
   "source": [
    "# The Data Science 'Pipeline'\n",
    "\n",
    "- The terms and the pipeline itself will most likely vary slightly, depending on where everything was learned, but at its core, it should be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40133308-480f-426c-9cd5-54a7a779e767",
   "metadata": {},
   "source": [
    "## Step One: Planning\n",
    "\n",
    "Pretty self explanatory, but there are certain things that should be defined by this phase.\n",
    "\n",
    "- The goal\n",
    "\n",
    "- Any deliverables\n",
    "\n",
    "- A rough 'How to get there'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9a730-c4c0-48a8-b026-e1bc7997dedb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### The Goal\n",
    "\n",
    "- Again, obvious. This is meant to define what your actual goal is, as well as your actual measure(s) of success. Also included are any plans on how to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3d5e1-fadd-4c13-97e1-87c3ba8373ed",
   "metadata": {},
   "source": [
    "### The Deliverable(s)\n",
    "\n",
    "- This will be the documentation of the goal, measure of success, and the plan to get there. If you don't define what success looks like to you, you won't know when you're there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46462a-561c-4b28-9cea-3c53b553d65f",
   "metadata": {},
   "source": [
    "### How to get There\n",
    "\n",
    "- This will be answered by asking questions *about* the final product and identifying any inital hypothesis to move forward with.\n",
    "\n",
    "- Common questions will be something like:\n",
    "\n",
    "    - What will the end product look like?\n",
    "    \n",
    "    - What format will it be in?\n",
    "    \n",
    "    - Who is it for?\n",
    "    \n",
    "    - What is my MVP (Minimal Viable Product)\n",
    "    \n",
    "- Formulating hypothesis will look something like this:\n",
    "\n",
    "    - Is attribute 1 (from the actual data) related to attribute 2?\n",
    "    \n",
    "    - How does attribute 3 relate to the target variable?\n",
    "    \n",
    "    - Is the mean of the target variable for subset A significantly different from subset B?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961e049-841c-43e9-a2b9-da43cc5c8682",
   "metadata": {},
   "source": [
    "## Step Two: Acquisition\n",
    "\n",
    "- The goal (for this step)\n",
    "\n",
    "- The deliverable\n",
    "\n",
    "- How to get there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f1aa02-887f-4230-9dc8-1a9c99141a97",
   "metadata": {},
   "source": [
    "### The Goal\n",
    "\n",
    "- You create a path from the original data sourceto the environment in which you're to be working with the data. In my case, I will acquire my data in such a way that I can work with it in Jupyter Labs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bc7f1-501b-4648-b4b7-70773a60a910",
   "metadata": {},
   "source": [
    "### The Deliverable\n",
    "\n",
    "- A file, the acquire.py (or alternatively encapsulated in a wrangle.py), that contans the functions needed to reproduce the acquisition of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42e887-a1d3-4d11-bf60-556d0a798299",
   "metadata": {},
   "source": [
    "### How to get There\n",
    "\n",
    "- There are any number of ways to get data, however one very common method is pulling the data from a SQL database. If this is used, some amount of refinement of the SQL query is probably necessary before reading the data into the python environment.\n",
    "\n",
    "- Another method would be to use Pandas to read the information directly from a csv, or json, txt, xlsx file (among others).\n",
    "\n",
    "- Web scraping using BeautifulSoup or even Selenium may be used to acquire this data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b5d90-06c8-4f5b-be4e-045149b8ab76",
   "metadata": {},
   "source": [
    "## Step Three: Preparation\n",
    "\n",
    "- The goal \n",
    "\n",
    "- The deliverable\n",
    "\n",
    "- How to get there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b97ac-dde3-40f2-b007-29c5776f6d8a",
   "metadata": {},
   "source": [
    "### The Goal\n",
    "\n",
    "- By the end of exploration you want to have your data split into 2 or 3 subsets (usually 3, but if cross-validation is being used later, then a train/test is optimal). This is done in order to have one sample of the data to use to test our final model, one that wasn't used in the exploration or development of the model, so that we can understand and see how our model works on 'future' unseen data, and determine generality and usefulness from there.\n",
    "\n",
    "- Before that, the data must be cleaned in a way that we can easily interpret.\n",
    "\n",
    "- With acquisition, preparation is absolutely one of the most time consuming parts of this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4649c-d7d5-4ca3-8857-da5dc5aada3e",
   "metadata": {},
   "source": [
    "### The Deliverable\n",
    "\n",
    "- As with the acquisition of the data, the deliverable here is a prepare.py file (or encapsulated within the wrangle.py mentioned above) with all of the functions used to clean the data so that the work is reproducible.  \n",
    "\n",
    "-  The resulting dataframes from this should be 2 or 3 samples\n",
    "\n",
    "- If the data is pslit 3 ways, there will be a train set, made for training the algorithms, a validate to...validate the models developed using the train, and a test set, made to test the data further on completely unseen data, in order to ensure the data can perform on new data and is not overfit. In this case the data splits should be somewhere be"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
